##Emotion-Based Music Recommendation System

#Overview

This project implements a real-time Emotion-Based Music Recommendation System using Streamlit, MediaPipe, and Keras. The system detects emotions from live video feeds, specifically through facial and hand landmarks, enabling personalized music suggestions based on the detected emotional state.

#Features

Real-time Emotion Detection: Utilizes MediaPipe and Keras models to detect emotions from live video streams.

Personalized Music Recommendations: Recommends music based on the detected emotions, enhancing user experience and engagement.

User-Friendly Interface: Streamlined user interaction via Streamlit for seamless input of language and singer preferences, delivering instant song suggestions aligned with emotional preferences.

Machine Learning Integration: Integrated machine learning models to accurately predict emotions from facial and hand landmarks, ensuring precise emotion detection.

#Technologies Used

Python: Core programming language for the project.

Streamlit: Framework used to create the user interface.

MediaPipe: Library for real-time hand and facial landmark detection.

Keras: Utilized for machine learning models for emotion prediction.

Git/GitHub: Version control and repository hosting.
